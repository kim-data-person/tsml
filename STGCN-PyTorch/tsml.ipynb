{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from utils import load_metr_la_data, normalize_data, split_dataset\n",
    "from stgcn import STGCN\n",
    "from train_epoch import train_epoch\n",
    "\n",
    "use_gpu = False\n",
    "num_timesteps_input = 12\n",
    "num_timesteps_output = 3\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 50\n",
    "\n",
    "torch.manual_seed(7) # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, X = load_metr_la_data()\n",
    "A_wave, X, means, stds = normalize_data(A, X)\n",
    "data = split_dataset(X, num_timesteps_input, num_timesteps_output)\n",
    "\n",
    "train_input = data['train_input'] # ([20549, 207, 12, 2])\n",
    "train_target = data['train_target'] # ([20549, 207, 3])\n",
    "val_input = data['val_input'] # ([6840, 207, 12, 2])\n",
    "val_target = data['val_target'] # ([6840, 207, 3])\n",
    "test_input = data['test_input'] # [6841, 207, 12, 2])\n",
    "test_target = data['test_target'] # ([6841, 207, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "A_wave = A_wave.to(device=device) \n",
    "\n",
    "model = STGCN(A_wave.shape[0], # nodes,\n",
    "            train_input.shape[3], # features\n",
    "            num_timesteps_input, \n",
    "            num_timesteps_output).to(device=device) \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_losses = []\n",
    "validation_losses = []\n",
    "validation_maes = []\n",
    "for epoch in range(epochs):\n",
    "    # 1 epoch training takes ~5 minutes\n",
    "    loss = train_epoch(A_wave=A_wave, model=model, loss_criterion=loss_criterion, optimizer=optimizer, \n",
    "                        train_input=train_input, train_target=train_target,\n",
    "                        batch_size=batch_size, device=device) # batch averaged loss of one epoch\n",
    "    training_losses.append(loss)\n",
    "\n",
    "    # Run validation\n",
    "    with torch.no_grad(): # Disable gradient calculation for evaluation\n",
    "        model.eval() # Set model to evaluation mode\n",
    "        val_input = val_input.to(device=device)\n",
    "        val_target = val_target.to(device=device)\n",
    "\n",
    "        prediction = model(A_wave, val_input)\n",
    "        val_loss = loss_criterion(prediction, val_target).to(device=\"cpu\")\n",
    "        validation_losses.append(val_loss.detach().numpy().item())\n",
    "\n",
    "        prediction_unnormalized = prediction.detach().cpu().numpy()*stds[0]+means[0]\n",
    "        target_unnormalized = val_target.detach().cpu().numpy()*stds[0]+means[0]\n",
    "        mae = np.mean(np.absolute(prediction_unnormalized - target_unnormalized))\n",
    "        validation_maes.append(mae)\n",
    "\n",
    "        prediction_unnormalized = None\n",
    "        val_input = val_input.to(device=\"cpu\")\n",
    "        val_target = val_target.to(device=\"cpu\")\n",
    "\n",
    "    if epochs % 10 == 0:\n",
    "        print(\"epochs: \", epochs, \n",
    "              \"Training loss: {}\".format(training_losses[-1]),\n",
    "              \"Validation loss: {}\".format(validation_losses[-1]))\n",
    "        #print(\"Validation MAE: {}\".format(validation_maes[-1]))\n",
    "\n",
    "    checkpoint_path = \"checkpoints/\"\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "    with open(\"checkpoints/losses.pk\", \"wb\") as fd:\n",
    "        pk.dump((training_losses, validation_losses, validation_maes), fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_losses, label=\"training loss\")\n",
    "plt.plot(validation_losses, label=\"validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsml",
   "language": "python",
   "name": "tsml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
